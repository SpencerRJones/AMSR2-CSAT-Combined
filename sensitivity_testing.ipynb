{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da767f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2cb21eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01-01\n",
      "2015-01-02\n",
      "2015-01-03\n",
      "2015-01-04\n",
      "2015-01-05\n",
      "2015-01-06\n",
      "2015-01-07\n",
      "2015-01-08\n",
      "2015-01-09\n",
      "2015-01-10\n",
      "2015-01-11\n",
      "2015-01-12\n",
      "2015-01-13\n",
      "2015-01-14\n",
      "2015-01-15\n",
      "2015-01-16\n",
      "2015-01-17\n",
      "2015-01-18\n",
      "2015-01-19\n",
      "2015-01-20\n",
      "2015-01-21\n",
      "2015-01-22\n",
      "2015-01-23\n",
      "2015-01-24\n",
      "2015-01-25\n",
      "2015-01-26\n",
      "2015-01-27\n",
      "2015-01-28\n",
      "2015-01-29\n",
      "2015-01-30\n",
      "2015-01-31\n",
      "Done!\n",
      "nbad:  3\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------\n",
    "#\n",
    "# averaging kernel testing - 15km\n",
    "#\n",
    "#-------------------------------------\n",
    "\n",
    "data_dir = '/edata2/spencer/thesis_data/sensitivity_testing/outputs/retrievals/'\n",
    "\n",
    "beg_date = '2015-01-01'\n",
    "end_date = '2015-01-31'\n",
    "beg_date = np.datetime64(beg_date)\n",
    "end_date = np.datetime64(end_date)\n",
    "\n",
    "first = True\n",
    "\n",
    "nbad = 0\n",
    "\n",
    "for idate in np.arange(beg_date, end_date + np.timedelta64(1, 'D')):\n",
    "    print(idate)\n",
    "    \n",
    "    cdate = str(idate).replace('-', '')\n",
    "    \n",
    "    flist = glob.glob(f'{data_dir}{cdate[:-2]}/{cdate}/*_v1.0_15km.nc')\n",
    "    flist.sort()\n",
    "    \n",
    "    if len(flist) == 0:\n",
    "        continue\n",
    "        \n",
    "    #---All retrievals\n",
    "    with xr.open_mfdataset(flist, combine='nested', concat_dim='npix') as f:\n",
    "        ac_lat = f.Latitude.values\n",
    "        ac_lon = f.Longitude.values\n",
    "        ac_chi = f.ChiSquared.values\n",
    "        ac_prcp = f.SurfacePrecip.values\n",
    "        ac_flg = f.RetrievalFlag.values\n",
    "    \n",
    "        \n",
    "        #Get valid data only:\n",
    "        converged = np.logical_and(ac_chi > 0., ac_chi <= 2.)\n",
    "        \n",
    "        good = np.where(converged)[0]\n",
    "    \n",
    "        ac_lat = ac_lat[good]\n",
    "        ac_lon = ac_lon[good]\n",
    "        ac_chi = ac_chi[good]\n",
    "        ac_prcp = ac_prcp[good]\n",
    "        \n",
    "        \n",
    "        if np.any(ac_prcp < 0.):\n",
    "            bad = np.where(ac_prcp < 0.)[0]\n",
    "            nbad += bad.size\n",
    "            ac_prcp = np.delete(ac_prcp,bad)\n",
    "            ac_chi  = np.delete(ac_chi, bad)\n",
    "    \n",
    "#     ac_lon[np.where(ac_lon < 0.)] = ac_lon[np.where(ac_lon < 0.)] + 360.\n",
    "    \n",
    "#     lat_indcs = (ac_lat.round() + 90).astype(int)\n",
    "#     lon_indcs = (ac_lon.round()).astype(int)\n",
    "    \n",
    "#     if np.any(lon_indcs > 359): lon_indcs[np.where(lon_indcs > 359)] = 0. \n",
    "        \n",
    "#     for i in np.arange(0, ac_lat.size):\n",
    "#         if ac_prcp[i] < 0.:\n",
    "#             nbad += 1\n",
    "#             continue\n",
    "#         a2cs_prcp_accum[lat_indcs[i], lon_indcs[i]] += ac_prcp[i]\n",
    "#         a2cs_prcp_counts[lat_indcs[i],lon_indcs[i]] += 1.\n",
    "    \n",
    "    \n",
    "# a2cs_mean_prcp = (a2cs_prcp_accum / a2cs_prcp_counts) * 24\n",
    "\n",
    "    if first:\n",
    "        all_ac_chi_15 = ac_chi\n",
    "        all_ac_prcp_15 = ac_prcp\n",
    "        \n",
    "        first = False\n",
    "        \n",
    "    else:\n",
    "        all_ac_chi_15 = np.append(all_ac_chi_15, ac_chi)\n",
    "        all_ac_prcp_15 = np.append(all_ac_prcp_15, ac_prcp)\n",
    "        \n",
    "\n",
    "print('Done!')\n",
    "print('nbad: ', nbad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d062cfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01-01\n",
      "2015-01-02\n",
      "2015-01-03\n",
      "2015-01-04\n",
      "2015-01-05\n",
      "2015-01-06\n",
      "2015-01-07\n",
      "2015-01-08\n",
      "2015-01-09\n",
      "2015-01-10\n",
      "2015-01-11\n",
      "2015-01-12\n",
      "2015-01-13\n",
      "2015-01-14\n",
      "2015-01-15\n",
      "2015-01-16\n",
      "2015-01-17\n",
      "2015-01-18\n",
      "2015-01-19\n",
      "2015-01-20\n",
      "2015-01-21\n",
      "2015-01-22\n",
      "2015-01-23\n",
      "2015-01-24\n",
      "2015-01-25\n",
      "2015-01-26\n",
      "2015-01-27\n",
      "2015-01-28\n",
      "2015-01-29\n",
      "2015-01-30\n",
      "2015-01-31\n",
      "Done!\n",
      "nbad:  5\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------\n",
    "#\n",
    "# averaging kernel testing - 30km\n",
    "#\n",
    "#-------------------------------------\n",
    "\n",
    "data_dir = '/edata2/spencer/OE/amsr2_radar/outputs/retrievals/'\n",
    "\n",
    "beg_date = '2015-01-01'\n",
    "end_date = '2015-01-31'\n",
    "beg_date = np.datetime64(beg_date)\n",
    "end_date = np.datetime64(end_date)\n",
    "\n",
    "first = True\n",
    "\n",
    "nbad = 0\n",
    "\n",
    "for idate in np.arange(beg_date, end_date + np.timedelta64(1, 'D')):\n",
    "    print(idate)\n",
    "    \n",
    "    cdate = str(idate).replace('-', '')\n",
    "    \n",
    "    flist = glob.glob(f'{data_dir}{cdate[:-2]}/{cdate}/*_v1.0.nc')\n",
    "    flist.sort()\n",
    "    \n",
    "    if len(flist) == 0:\n",
    "        continue\n",
    "        \n",
    "    #---All retrievals\n",
    "    with xr.open_mfdataset(flist, combine='nested', concat_dim='npix') as f:\n",
    "        ac_lat = f.Latitude.values\n",
    "        ac_lon = f.Longitude.values\n",
    "        ac_chi = f.ChiSquared.values\n",
    "        ac_prcp = f.SurfacePrecip.values\n",
    "        ac_flg = f.RetrievalFlag.values\n",
    "    \n",
    "        \n",
    "        #Get valid data only:\n",
    "        converged = np.logical_and(ac_chi > 0., ac_chi <= 2.)\n",
    "        \n",
    "        good = np.where(converged)[0]\n",
    "    \n",
    "        ac_lat = ac_lat[good]\n",
    "        ac_lon = ac_lon[good]\n",
    "        ac_chi = ac_chi[good]\n",
    "        ac_prcp = ac_prcp[good]\n",
    "        \n",
    "        \n",
    "        if np.any(ac_prcp < 0.):\n",
    "            bad = np.where(ac_prcp < 0.)[0]\n",
    "            nbad += bad.size\n",
    "            ac_prcp = np.delete(ac_prcp,bad)\n",
    "            ac_chi  = np.delete(ac_chi, bad)\n",
    "    \n",
    "#     ac_lon[np.where(ac_lon < 0.)] = ac_lon[np.where(ac_lon < 0.)] + 360.\n",
    "    \n",
    "#     lat_indcs = (ac_lat.round() + 90).astype(int)\n",
    "#     lon_indcs = (ac_lon.round()).astype(int)\n",
    "    \n",
    "#     if np.any(lon_indcs > 359): lon_indcs[np.where(lon_indcs > 359)] = 0. \n",
    "        \n",
    "#     for i in np.arange(0, ac_lat.size):\n",
    "#         if ac_prcp[i] < 0.:\n",
    "#             nbad += 1\n",
    "#             continue\n",
    "#         a2cs_prcp_accum[lat_indcs[i], lon_indcs[i]] += ac_prcp[i]\n",
    "#         a2cs_prcp_counts[lat_indcs[i],lon_indcs[i]] += 1.\n",
    "    \n",
    "    \n",
    "# a2cs_mean_prcp = (a2cs_prcp_accum / a2cs_prcp_counts) * 24\n",
    "\n",
    "    if first:\n",
    "        all_ac_chi_30 = ac_chi\n",
    "        all_ac_prcp_30 = ac_prcp\n",
    "        \n",
    "        first = False\n",
    "        \n",
    "    else:\n",
    "        all_ac_chi_30 = np.append(all_ac_chi_30, ac_chi)\n",
    "        all_ac_prcp_30 = np.append(all_ac_prcp_30, ac_prcp)\n",
    "        \n",
    "\n",
    "print('Done!')\n",
    "print('nbad: ', nbad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbe49600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01-01\n",
      "2015-01-02\n",
      "2015-01-03\n",
      "2015-01-04\n",
      "2015-01-05\n",
      "2015-01-06\n",
      "2015-01-07\n",
      "2015-01-08\n",
      "2015-01-09\n",
      "2015-01-10\n",
      "2015-01-11\n",
      "2015-01-12\n",
      "2015-01-13\n",
      "2015-01-14\n",
      "2015-01-15\n",
      "2015-01-16\n",
      "2015-01-17\n",
      "2015-01-18\n",
      "2015-01-19\n",
      "2015-01-20\n",
      "2015-01-21\n",
      "2015-01-22\n",
      "2015-01-23\n",
      "2015-01-24\n",
      "2015-01-25\n",
      "2015-01-26\n",
      "2015-01-27\n",
      "2015-01-28\n",
      "2015-01-29\n",
      "2015-01-30\n",
      "2015-01-31\n",
      "Done!\n",
      "nbad:  4\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------\n",
    "#\n",
    "# averaging kernel testing - 45km\n",
    "#\n",
    "#-------------------------------------\n",
    "\n",
    "data_dir = '/edata2/spencer/thesis_data/sensitivity_testing/outputs/retrievals/'\n",
    "\n",
    "beg_date = '2015-01-01'\n",
    "end_date = '2015-01-31'\n",
    "beg_date = np.datetime64(beg_date)\n",
    "end_date = np.datetime64(end_date)\n",
    "\n",
    "first = True\n",
    "\n",
    "nbad = 0\n",
    "\n",
    "for idate in np.arange(beg_date, end_date + np.timedelta64(1, 'D')):\n",
    "    print(idate)\n",
    "    \n",
    "    cdate = str(idate).replace('-', '')\n",
    "    \n",
    "    flist = glob.glob(f'{data_dir}{cdate[:-2]}/{cdate}/*_v1.0_45km.nc')\n",
    "    flist.sort()\n",
    "    \n",
    "    if len(flist) == 0:\n",
    "        continue\n",
    "        \n",
    "    #---All retrievals\n",
    "    with xr.open_mfdataset(flist, combine='nested', concat_dim='npix') as f:\n",
    "        ac_lat = f.Latitude.values\n",
    "        ac_lon = f.Longitude.values\n",
    "        ac_chi = f.ChiSquared.values\n",
    "        ac_prcp = f.SurfacePrecip.values\n",
    "        ac_flg = f.RetrievalFlag.values\n",
    "    \n",
    "        \n",
    "        #Get valid data only:\n",
    "        converged = np.logical_and(ac_chi > 0., ac_chi <= 2.)\n",
    "        \n",
    "        good = np.where(converged)[0]\n",
    "    \n",
    "        ac_lat = ac_lat[good]\n",
    "        ac_lon = ac_lon[good]\n",
    "        ac_chi = ac_chi[good]\n",
    "        ac_prcp = ac_prcp[good]\n",
    "        \n",
    "        \n",
    "        if np.any(ac_prcp < 0.):\n",
    "            bad = np.where(ac_prcp < 0.)[0]\n",
    "            nbad += bad.size\n",
    "            ac_prcp = np.delete(ac_prcp,bad)\n",
    "            ac_chi  = np.delete(ac_chi, bad)\n",
    "    \n",
    "#     ac_lon[np.where(ac_lon < 0.)] = ac_lon[np.where(ac_lon < 0.)] + 360.\n",
    "    \n",
    "#     lat_indcs = (ac_lat.round() + 90).astype(int)\n",
    "#     lon_indcs = (ac_lon.round()).astype(int)\n",
    "    \n",
    "#     if np.any(lon_indcs > 359): lon_indcs[np.where(lon_indcs > 359)] = 0. \n",
    "        \n",
    "#     for i in np.arange(0, ac_lat.size):\n",
    "#         if ac_prcp[i] < 0.:\n",
    "#             nbad += 1\n",
    "#             continue\n",
    "#         a2cs_prcp_accum[lat_indcs[i], lon_indcs[i]] += ac_prcp[i]\n",
    "#         a2cs_prcp_counts[lat_indcs[i],lon_indcs[i]] += 1.\n",
    "    \n",
    "    \n",
    "# a2cs_mean_prcp = (a2cs_prcp_accum / a2cs_prcp_counts) * 24\n",
    "\n",
    "    if first:\n",
    "        all_ac_chi_45 = ac_chi\n",
    "        all_ac_prcp_45 = ac_prcp\n",
    "        \n",
    "        first = False\n",
    "        \n",
    "    else:\n",
    "        all_ac_chi_45 = np.append(all_ac_chi_45, ac_chi)\n",
    "        all_ac_prcp_45 = np.append(all_ac_prcp_45, ac_prcp)\n",
    "        \n",
    "\n",
    "print('Done!')\n",
    "print('nbad: ', nbad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1781ca5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01-01\n",
      "2015-01-02\n",
      "2015-01-03\n",
      "2015-01-04\n",
      "2015-01-05\n",
      "2015-01-06\n",
      "2015-01-07\n",
      "2015-01-08\n",
      "2015-01-09\n",
      "2015-01-10\n",
      "2015-01-11\n",
      "2015-01-12\n",
      "2015-01-13\n",
      "2015-01-14\n",
      "2015-01-15\n",
      "2015-01-16\n",
      "2015-01-17\n",
      "2015-01-18\n",
      "2015-01-19\n",
      "2015-01-20\n",
      "2015-01-21\n",
      "2015-01-22\n",
      "2015-01-23\n",
      "2015-01-24\n",
      "2015-01-25\n",
      "2015-01-26\n",
      "2015-01-27\n",
      "2015-01-28\n",
      "2015-01-29\n",
      "2015-01-30\n",
      "2015-01-31\n",
      "Done!\n",
      "nbad:  0\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------\n",
    "#\n",
    "# averaging kernel testing - 60km\n",
    "#\n",
    "#-------------------------------------\n",
    "\n",
    "data_dir = '/edata2/spencer/thesis_data/sensitivity_testing/outputs/retrievals/'\n",
    "\n",
    "beg_date = '2015-01-01'\n",
    "end_date = '2015-01-31'\n",
    "beg_date = np.datetime64(beg_date)\n",
    "end_date = np.datetime64(end_date)\n",
    "\n",
    "first = True\n",
    "\n",
    "nbad = 0\n",
    "\n",
    "for idate in np.arange(beg_date, end_date + np.timedelta64(1, 'D')):\n",
    "    print(idate)\n",
    "    \n",
    "    cdate = str(idate).replace('-', '')\n",
    "    \n",
    "    flist = glob.glob(f'{data_dir}{cdate[:-2]}/{cdate}/*_v1.0_60km.nc')\n",
    "    flist.sort()\n",
    "    \n",
    "    if len(flist) == 0:\n",
    "        continue\n",
    "        \n",
    "    #---All retrievals\n",
    "    with xr.open_mfdataset(flist, combine='nested', concat_dim='npix') as f:\n",
    "        ac_lat = f.Latitude.values\n",
    "        ac_lon = f.Longitude.values\n",
    "        ac_chi = f.ChiSquared.values\n",
    "        ac_prcp = f.SurfacePrecip.values\n",
    "        ac_flg = f.RetrievalFlag.values\n",
    "    \n",
    "        \n",
    "        #Get valid data only:\n",
    "        converged = np.logical_and(ac_chi > 0., ac_chi <= 2.)\n",
    "        \n",
    "        good = np.where(converged)[0]\n",
    "    \n",
    "        ac_lat = ac_lat[good]\n",
    "        ac_lon = ac_lon[good]\n",
    "        ac_chi = ac_chi[good]\n",
    "        ac_prcp = ac_prcp[good]\n",
    "        \n",
    "        \n",
    "        if np.any(ac_prcp < 0.):\n",
    "            bad = np.where(ac_prcp < 0.)[0]\n",
    "            nbad += bad.size\n",
    "            ac_prcp = np.delete(ac_prcp,bad)\n",
    "            ac_chi  = np.delete(ac_chi, bad)\n",
    "    \n",
    "#     ac_lon[np.where(ac_lon < 0.)] = ac_lon[np.where(ac_lon < 0.)] + 360.\n",
    "    \n",
    "#     lat_indcs = (ac_lat.round() + 90).astype(int)\n",
    "#     lon_indcs = (ac_lon.round()).astype(int)\n",
    "    \n",
    "#     if np.any(lon_indcs > 359): lon_indcs[np.where(lon_indcs > 359)] = 0. \n",
    "        \n",
    "#     for i in np.arange(0, ac_lat.size):\n",
    "#         if ac_prcp[i] < 0.:\n",
    "#             nbad += 1\n",
    "#             continue\n",
    "#         a2cs_prcp_accum[lat_indcs[i], lon_indcs[i]] += ac_prcp[i]\n",
    "#         a2cs_prcp_counts[lat_indcs[i],lon_indcs[i]] += 1.\n",
    "    \n",
    "    \n",
    "# a2cs_mean_prcp = (a2cs_prcp_accum / a2cs_prcp_counts) * 24\n",
    "\n",
    "    if first:\n",
    "        all_ac_chi_60 = ac_chi\n",
    "        all_ac_prcp_60 = ac_prcp\n",
    "        \n",
    "        first = False\n",
    "        \n",
    "    else:\n",
    "        all_ac_chi_60 = np.append(all_ac_chi_60, ac_chi)\n",
    "        all_ac_prcp_60 = np.append(all_ac_prcp_60, ac_prcp)\n",
    "        \n",
    "\n",
    "print('Done!')\n",
    "print('nbad: ', nbad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9619c59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean prcp: \n",
      "15 km:  0.058818564\n",
      "30 km:  0.061929982\n",
      "45 km:  0.06406271\n",
      "60 km:  0.018617868\n"
     ]
    }
   ],
   "source": [
    "mean_prcp_15 = all_ac_prcp_15.mean()\n",
    "mean_prcp_30 = all_ac_prcp_30.mean()\n",
    "mean_prcp_45 = all_ac_prcp_45.mean()\n",
    "mean_prcp_60 = all_ac_prcp_60.mean()\n",
    "\n",
    "print('Mean prcp: ')\n",
    "print('15 km: ', mean_prcp_15)\n",
    "print('30 km: ', mean_prcp_30)\n",
    "print('45 km: ', mean_prcp_45)\n",
    "print('60 km: ', mean_prcp_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e044696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent difference 15 km:  -0.050240904\n",
      "Percent difference 45 km:  0.034437682\n"
     ]
    }
   ],
   "source": [
    "prc_diff_15 = (mean_prcp_15 - mean_prcp_30) / mean_prcp_30\n",
    "prc_diff_45 = (mean_prcp_45 - mean_prcp_30) / mean_prcp_30\n",
    "\n",
    "print('Percent difference 15 km: ', prc_diff_15)\n",
    "print('Percent difference 45 km: ', prc_diff_45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3019a90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
